# Reddit Problem Scraper & AI Assistant

Un SaaS pour scraper les problÃ¨mes des utilisateurs Reddit et fournir des rÃ©ponses intelligentes via un chatbot.

## ğŸ¯ FonctionnalitÃ©s

### Scraping Reddit
- **Subreddits franÃ§ais** : r/france, r/QueFaire
- **Subreddits internationaux** : r/AskReddit, r/Entrepreneur, r/SaaS
- Extraction automatique des problÃ¨mes et questions
- Stockage structurÃ© en base de donnÃ©es

### Chatbot IA
- Analyse contextuelle des problÃ¨mes
- RÃ©ponses personnalisÃ©es basÃ©es sur les donnÃ©es scrapÃ©es
- Recherche intelligente dans les forums spÃ©cifiques
- Interface conversationnelle intuitive

### SaaS avec Next.js
- Interface moderne et responsive
- SystÃ¨me d'authentification
- Plans d'abonnement avec Stripe
- Dashboard utilisateur

## ğŸ—ï¸ Architecture

```
Projet_01/
â”œâ”€â”€ Backend/                 # API FastAPI
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ scrapers/        # Scrapers Reddit
â”‚   â”‚   â”œâ”€â”€ chatbot/         # Logique IA
â”‚   â”‚   â”œâ”€â”€ api/             # Endpoints API
â”‚   â”‚   â””â”€â”€ models/          # ModÃ¨les de donnÃ©es
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ Frontend/                # Next.js App
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # Composants React
â”‚   â”‚   â”œâ”€â”€ pages/           # Pages Next.js
â”‚   â”‚   â”œâ”€â”€ hooks/           # Hooks personnalisÃ©s
â”‚   â”‚   â””â”€â”€ utils/           # Utilitaires
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ next.config.js
â””â”€â”€ README.md
```

## ğŸš€ Installation

### PrÃ©requis
- Python 3.8+
- Node.js 18+
- Compte Supabase
- Redis (optionnel)
- Comptes API : Reddit, OpenAI, Stripe

### Configuration

1. **Cloner le projet**
```bash
git clone <votre-repo>
cd Projet_01
```

2. **Configuration Backend**
```bash
cd Backend
cp env.example .env
# Ã‰diter .env avec vos clÃ©s API
```

3. **Configuration Frontend**
```bash
cd Frontend
cp .env.example .env.local
# Ã‰diter .env.local avec vos clÃ©s API
```

### Variables d'environnement

**Backend (.env)**
```env
# Supabase
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key

# Reddit API
REDDIT_CLIENT_ID=your_reddit_client_id
REDDIT_CLIENT_SECRET=your_reddit_client_secret

# OpenAI
OPENAI_API_KEY=your_openai_api_key

# Stripe
STRIPE_SECRET_KEY=sk_test_your_stripe_secret_key
STRIPE_PUBLISHABLE_KEY=pk_test_your_stripe_publishable_key
STRIPE_WEBHOOK_SECRET=whsec_your_stripe_webhook_secret
```

**Frontend (.env.local)**
```env
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY=pk_test_your_stripe_publishable_key
```

### Installation des dÃ©pendances

**Backend**
```bash
cd Backend
python -m venv venv
source venv/bin/activate  # ou `venv\Scripts\activate` sur Windows
pip install -r requirements.txt
```

**Frontend**
```bash
cd Frontend
npm install
```

### Configuration Supabase

1. **CrÃ©er un projet Supabase**
   - Aller sur [supabase.com](https://supabase.com)
   - CrÃ©er un nouveau projet
   - Noter l'URL et les clÃ©s API

2. **Configurer la base de donnÃ©es**
   - Aller dans l'Ã©diteur SQL de Supabase
   - ExÃ©cuter le script `Backend/supabase_schema.sql`
   - Cela crÃ©era toutes les tables et politiques de sÃ©curitÃ©

3. **Configurer l'authentification**
   - Dans Supabase Dashboard > Authentication > Settings
   - Configurer les providers souhaitÃ©s (Email, Google, etc.)
   - Activer "Enable email confirmations" si nÃ©cessaire

### Lancement

**Backend**
```bash
cd Backend
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

**Frontend**
```bash
cd Frontend
npm run dev
```

L'application sera disponible sur :
- Frontend : http://localhost:3000
- Backend API : http://localhost:8000
- Documentation API : http://localhost:8000/docs

## ğŸ“Š Subreddits CiblÃ©s

### ğŸ‡«ğŸ‡· FranÃ§ais
- r/france - ProblÃ¨mes gÃ©nÃ©raux
- r/QueFaire - Questions et conseils

### ğŸŒ International
- r/AskReddit - Questions gÃ©nÃ©rales
- r/Entrepreneur - ProblÃ¨mes entrepreneuriaux
- r/SaaS - ProblÃ¨mes SaaS

## ğŸ’° Plans SaaS

- **Gratuit** : 10 requÃªtes/mois
- **Pro** : 100 requÃªtes/mois - $9.99/mois
- **Business** : RequÃªtes illimitÃ©es - $29.99/mois

## ğŸ”§ Technologies

- **Backend** : FastAPI, PRAW (Reddit API), OpenAI Agent SDK
- **Frontend** : Next.js, TypeScript, Tailwind CSS
- **Base de donnÃ©es** : Supabase (PostgreSQL + Auth + Real-time)
- **Paiement** : Stripe
- **DÃ©ploiement** : Vercel (Frontend) + Railway/Heroku (Backend)

## ğŸ“– Utilisation

### 1. Scraping Reddit
```bash
# Scraper tous les subreddits
curl -X POST http://localhost:8000/api/scraping/scrape-all

# Scraper un subreddit spÃ©cifique
curl -X POST http://localhost:8000/api/scraping/scrape-subreddit/france
```

### 2. Chatbot IA
```bash
# Chat avec l'agent
curl -X POST http://localhost:8000/api/chatbot/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Comment gÃ©rer le stress au travail ?",
    "language": "fr"
  }'
```

### 3. API Endpoints principaux

**Scraping**
- `POST /api/scraping/scrape-all` - Scraper tous les subreddits
- `POST /api/scraping/scrape-subreddit/{name}` - Scraper un subreddit
- `GET /api/scraping/posts` - RÃ©cupÃ©rer les posts scrapÃ©s
- `GET /api/scraping/posts/stats` - Statistiques des posts

**Chatbot**
- `POST /api/chatbot/chat` - Chat avec l'agent IA
- `GET /api/chatbot/sessions` - Sessions de chat
- `POST /api/chatbot/search-problems` - Recherche de problÃ¨mes

**Authentification**
- `POST /api/auth/register` - Inscription
- `POST /api/auth/login` - Connexion
- `GET /api/auth/me` - Profil utilisateur

**Abonnement**
- `GET /api/subscription/plans` - Plans disponibles
- `POST /api/subscription/create-checkout-session` - CrÃ©er paiement
- `GET /api/subscription/current` - Abonnement actuel

## ğŸš€ Prochaines Ã©tapes

### Phase 1 - MVP (2-3 semaines)
- [ ] Finaliser l'authentification JWT
- [ ] ImplÃ©menter le systÃ¨me de quotas
- [ ] CrÃ©er l'interface de chat
- [ ] Ajouter les pages de tarification
- [ ] IntÃ©grer Stripe

### Phase 2 - FonctionnalitÃ©s avancÃ©es (4-6 semaines)
- [ ] Dashboard utilisateur
- [ ] Export de donnÃ©es
- [ ] Notifications en temps rÃ©el
- [ ] API publique
- [ ] Analytics avancÃ©es

### Phase 3 - Scale (6-8 semaines)
- [ ] Cache Redis
- [ ] Background jobs avec Celery
- [ ] Monitoring et logging
- [ ] Tests automatisÃ©s
- [ ] CI/CD pipeline

### Phase 4 - DÃ©ploiement (2-3 semaines)
- [ ] Configuration production
- [ ] SSL et sÃ©curitÃ©
- [ ] Monitoring production
- [ ] Documentation utilisateur
- [ ] Support client

## ğŸ” SÃ©curitÃ©

- Authentification Supabase Auth (JWT sÃ©curisÃ©)
- Row Level Security (RLS) sur toutes les tables
- Validation des donnÃ©es avec Pydantic
- Rate limiting sur les API
- CORS configurÃ©
- Variables d'environnement sÃ©curisÃ©es
- Politiques de sÃ©curitÃ© granulaires

## ğŸ“ˆ Monitoring

- Logs structurÃ©s
- MÃ©triques de performance
- Alertes d'erreurs
- Dashboard de santÃ©
- Analytics d'utilisation

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de dÃ©tails.
